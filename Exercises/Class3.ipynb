{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose function - Covulational to Images \n",
    "f(Img) â†’ bird\n",
    "\n",
    "I used Cifar10 lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/content/drive/MyDrive/datasets'\n",
    "DATA_DIR = '/content/drive/MyDrive/datasets/cifar10'\n",
    "CATEGORIES = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "def get_path(relpath):\n",
    "  return os.path.join(BASE_DIR, relpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_train = CIFAR10(DATA_DIR, train=True, download=True)\n",
    "cifar10_test = CIFAR10(DATA_DIR, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(cifar10_train), len(cifar10_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result: \n",
    "\n",
    "*(50000, 10000)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookat_dataset(dataset, istensor=False):\n",
    "  figure = plt.figure(figsize=(8, 8))\n",
    "  rows, cols = 2, 2\n",
    "  for i in range(1, 5):\n",
    "      sample_idx = torch.randint(len(dataset), size=(1,)).item()\n",
    "      img, label = dataset[sample_idx]\n",
    "      figure.add_subplot(rows, cols, i)\n",
    "      plt.title(CATEGORIES[label])\n",
    "      plt.axis(\"off\")\n",
    "      if istensor:\n",
    "        plt.imshow(img.squeeze().permute(1, 2, 0))\n",
    "      else:\n",
    "        plt.imshow(img)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookat_dataset(cifar10_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Result:\n",
    "\n",
    "![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3d7f32a3-eddd-46e3-a6ee-4a4f8ffd2aab/aaeffd09-bbf2-47cf-a464-28a981f96abc/Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_transform = T.Compose([\n",
    "                    T.ToTensor()\n",
    "                  ])\n",
    "\n",
    "# Applying a transform\n",
    "tensor_train = CIFAR10(DATA_DIR, train=True, download=False,\n",
    "                         transform=prep_transform)\n",
    "tensor_test = CIFAR10(DATA_DIR, train=False, download=False,\n",
    "                         transform=prep_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need identfy the labels to normalize\n",
    "# Normalizing data\n",
    "imgs = torch.stack([img_t for img_t, _ in tensor_train], dim=3)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.view(3, -1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.view(3, -1).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_transform = T.Compose([\n",
    "                    T.ToTensor(),\n",
    "\t\t\t\t\t\t\t\t\t\t#O normalize added with numbers found.\n",
    "                    T.Normalize(\n",
    "                        (0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)\n",
    "                    )\n",
    "                  ])\n",
    "\n",
    "# Applying a transform\n",
    "tensor_train = CIFAR10(DATA_DIR, train=True, download=False,\n",
    "                         transform=prep_transform)\n",
    "tensor_test = CIFAR10(DATA_DIR, train=False, download=False,\n",
    "                         transform=prep_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookat_dataset(tensor_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results: \n",
    "![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3d7f32a3-eddd-46e3-a6ee-4a4f8ffd2aab/463b78f1-eeec-4846-8865-e95347290b84/Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(tensor_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(tensor_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    \n",
    "    self.layers = nn.Sequential(\n",
    "\t\t\t\t#3=RGB, 32*32=image size, break blocks\n",
    "        nn.Linear(3 * 32*32, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 10),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    v = self.flatten(x)\n",
    "    return self.layers(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Run on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_func, optimizer):\n",
    "  model.train()\n",
    "  cumloss = 0.0\n",
    "\n",
    "  for imgs, labels in dataloader:\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(imgs)\n",
    "\n",
    "    loss = loss_func(pred, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    cumloss += loss.item()\n",
    "\n",
    "  return cumloss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, loss_func):\n",
    "  model.eval()\n",
    "  cumloss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for imgs, labels in dataloader:\n",
    "      imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "      pred = model(imgs)\n",
    "      loss = loss_func(pred, labels)\n",
    "      cumloss += loss.item()\n",
    "\n",
    "  return cumloss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "  fig = plt.figure(figsize=(13, 5))\n",
    "  ax = fig.gca()\n",
    "  for loss_name, loss_values in losses.items():  \n",
    "    ax.plot(loss_values, label=loss_name)\n",
    "  ax.legend(fontsize=\"16\")\n",
    "  ax.set_xlabel(\"Iteration\", fontsize=\"16\")\n",
    "  ax.set_ylabel(\"Loss\", fontsize=\"16\")\n",
    "  ax.set_title(\"Loss vs iterations\", fontsize=\"16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See data loss on train\n",
    "epochs = 41\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for t in range(epochs):\n",
    "  train_loss = train(model, train_loader, loss_func, optimizer)\n",
    "  train_losses.append(train_loss)\n",
    "  if t % 10 == 0:\n",
    "    print(f\"Epoch: {t}; Train Loss: {train_loss}\")\n",
    "  \n",
    "  test_loss = validate(model, test_loader, loss_func)\n",
    "  test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"Train loss\": train_losses, \"Test loss\": test_losses}\n",
    "plot_losses(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result:\n",
    "![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3d7f32a3-eddd-46e3-a6ee-4a4f8ffd2aab/d001451f-1b73-4565-8976-22d07bc2ff5b/Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To evaluate results\n",
    "\n",
    "def make_confusion_matrix(model, loader, n_classes):\n",
    "  confusion_matrix = torch.zeros(n_classes, n_classes, dtype=torch.int64)\n",
    "  with torch.no_grad():\n",
    "    for i, (imgs, labels) in enumerate(loader):\n",
    "      imgs = imgs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      outputs = model(imgs)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      for t, p in zip(torch.as_tensor(labels, dtype=torch.int64).view(-1), \n",
    "                      torch.as_tensor(predicted, dtype=torch.int64).view(-1)):\n",
    "        confusion_matrix[t, p] += 1\n",
    "  return confusion_matrix\n",
    "\n",
    "def evaluate_accuracy(model, dataloader, classes, verbose=True):\n",
    "  # prepare to count predictions for each class\n",
    "  correct_pred = {classname: 0 for classname in classes}\n",
    "  total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "  confusion_matrix = make_confusion_matrix(model, dataloader, len(classes))\n",
    "  if verbose:\n",
    "    total_correct = 0.0\n",
    "    total_prediction = 0.0\n",
    "    for i, classname in enumerate(classes):\n",
    "      correct_count = confusion_matrix[i][i].item()\n",
    "      class_pred = torch.sum(confusion_matrix[i]).item()\n",
    "\n",
    "      total_correct += correct_count\n",
    "      total_prediction += class_pred\n",
    "\n",
    "      accuracy = 100 * float(correct_count) / class_pred\n",
    "      print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                    accuracy))\n",
    "  print(\"Global acccuracy is {:.1f}\".format(100 * total_correct/total_prediction))\n",
    "  return confusion_matrix\n",
    "\n",
    "def test(model, dataloader, classes):\n",
    "  # prepare to count predictions for each class\n",
    "  correct_pred = {classname: 0 for classname in classes}\n",
    "  total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "  # again no gradients needed\n",
    "  with torch.no_grad():\n",
    "      for images, labels in dataloader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          outputs = model(images)\n",
    "          _, predictions = torch.max(outputs, 1)\n",
    "          # collect the correct predictions for each class\n",
    "          for label, prediction in zip(labels, predictions):\n",
    "              if label == prediction:\n",
    "                  correct_pred[classes[label]] += 1\n",
    "              total_pred[classes[label]] += 1\n",
    "\n",
    "  # print accuracy for each class\n",
    "  total_correct = 0.0\n",
    "  total_prediction = 0.0\n",
    "  for classname, correct_count in correct_pred.items():\n",
    "      total_correct += correct_count\n",
    "      total_prediction += total_pred[classname]\n",
    "      accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "      print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                    accuracy))\n",
    "  print(\"Global acccuracy is {:.1f}\".format(100 * total_correct/total_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = evaluate_accuracy(model, test_loader, CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(confusion_matrix.tolist(), \n",
    "           annot=True, annot_kws={\"size\": 16}, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expeted Results:\n",
    "\n",
    "![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3d7f32a3-eddd-46e3-a6ee-4a4f8ffd2aab/eab8925b-84e9-4452-af4e-1e92b175f22d/Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inite covolutional network\n",
    "\n",
    "class ConvolutionalModel(nn.Module):\n",
    "  def __init__(self):\n",
    "      super().__init__()\n",
    "\t\t\t#layer covolutional 2D\n",
    "      self.convlayers = nn.Sequential(\n",
    "        nn.Conv2d(3, 16, kernel_size=(3, 3)),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "\n",
    "        nn.Conv2d(16, 32, kernel_size=(3, 3)),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "\n",
    "      )\n",
    "\t\t\t#classify\n",
    "      self.linearlayers = nn.Sequential(\n",
    "\t\t\t\t\t#simulate on CPU to see entry valor, or calculate with border difference.\n",
    "          nn.Linear(1152, 256),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(256, 10)\n",
    "      )\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.convlayers(x)\n",
    "      x = torch.flatten(x, 1)\n",
    "      return self.linearlayers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convmodel = ConvolutionalModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = torch.optim.SGD(convmodel.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 51\n",
    "conv_train_losses = []\n",
    "conv_test_losses = []\n",
    "for t in range(epochs):\n",
    "  train_loss = train(convmodel, train_loader, loss_func2, optimizer2)\n",
    "  conv_train_losses.append(train_loss)\n",
    "  if t % 10 == 0:\n",
    "    print(f\"Epoch: {t}; Train Loss: {train_loss}\")\n",
    "  test_loss = validate(convmodel, test_loader, loss_func2)\n",
    "  conv_test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_losses = {\"Train Loss\": conv_train_losses, \"Test Loss\": conv_test_losses}\n",
    "plot_losses(conv_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result:\n",
    "\n",
    "![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3d7f32a3-eddd-46e3-a6ee-4a4f8ffd2aab/a4d77a8a-4fff-4f56-b662-7fee839c1666/Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_confusion_matrix = evaluate_accuracy(convmodel, test_loader, CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(confusion_matrix.tolist(), \n",
    "           annot=True, annot_kws={\"size\": 16}, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result:\n",
    "\n",
    "![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3d7f32a3-eddd-46e3-a6ee-4a4f8ffd2aab/1615e07d-2d98-45ec-8961-1bb382a5a7a0/Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass your image to test here\n",
    "img = Image.open(get_path('/content/drive/MyDrive/angry.JPG'))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result:\n",
    "\n",
    "See your image \n",
    "\n",
    "![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3d7f32a3-eddd-46e3-a6ee-4a4f8ffd2aab/8bbb0647-faef-4ce8-ad0c-f5ab6c24087f/Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_transforms = T.Compose(\n",
    "    [T.Resize((32, 32)),\n",
    "     T.ToTensor(),\n",
    "     T.Normalize( (0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616) )\n",
    "     ]\n",
    ")\n",
    "img_tensor = prep_transforms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tensor.permute(1,2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result:\n",
    "\n",
    "See your image transformed\n",
    "![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3d7f32a3-eddd-46e3-a6ee-4a4f8ffd2aab/b7435336-76da-4547-874f-27f78247535d/Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = img_tensor.unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convmodel.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result:\n",
    "See your covolutional model\n",
    "\n",
    "ConvolutionalModel(\n",
    "(convlayers): Sequential(\n",
    "(0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
    "(1): ReLU()\n",
    "(2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "(3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
    "(4): ReLU()\n",
    "(5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    ")\n",
    "(linearlayers): Sequential(\n",
    "(0): Linear(in_features=1152, out_features=256, bias=True)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=256, out_features=10, bias=True)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = convmodel(batch)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.nn.functional.softmax(output, dim=1) * 100\n",
    "prob_dict = {}\n",
    "for i, classname in enumerate(CATEGORIES):\n",
    "  prob = logits[0][i].item()\n",
    "  print(f\"{classname} score: {prob:.2f}\")\n",
    "  prob_dict[classname] = [prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob = pd.DataFrame.from_dict(prob_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob.plot(kind='barh', figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result:\n",
    "\n",
    "![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/3d7f32a3-eddd-46e3-a6ee-4a4f8ffd2aab/6c527c41-12fa-4055-b6a8-f7748b496682/Untitled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your models\n",
    "\n",
    "torch.save(model.state_dict(), '/content/drive/MyDrive/mlp_model_weights.pth')\n",
    "\n",
    "torch.save(convmodel.state_dict(), '/content/drive/MyDrive/conv_model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
